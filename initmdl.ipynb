{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import unicodedata\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, hamming_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Path Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.getcwd()\n",
    "data_dir = os.path.join(base_dir, 'Data')\n",
    "\n",
    "#Source File Path\n",
    "in_data_pref = os.path.join(data_dir, 'Input')\n",
    "src_file_name = 'KaggleV2-May-2016.csv'\n",
    "src_data_path = os.path.join(in_data_pref , src_file_name)\n",
    "        \n",
    "#Read Source File\n",
    "df = pd.read_csv(src_data_path, index_col=None,\n",
    "                 parse_dates=[\"ScheduledDay\", \"AppointmentDay\"], infer_datetime_format=True\n",
    "                )\n",
    "\n",
    "#Load and Read Income data\n",
    "mean_income_fname = 'mean_incoming_neighborhood.csv'\n",
    "neigh_income_range_fname = 'incoming_range_neighborhood.csv'\n",
    "mean_income_path = os.path.join(in_data_pref , mean_income_fname)\n",
    "neigh_income_range_path = os.path.join(in_data_pref , neigh_income_range_fname)\n",
    "\n",
    "mean_income = pd.read_csv(mean_income_path, index_col=None)\n",
    "income_ranges = pd.read_csv(neigh_income_range_path, index_col=None)\n",
    "\n",
    "#Output File Path\n",
    "op_file_name = 'prediction.json'\n",
    "op_data_pref = os.path.join(data_dir, 'Output')\n",
    "op_data_path = os.path.join(op_data_pref , src_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camelcase_to_snakecase(name):\n",
    "    s1 = re.sub('(.)([A-Z][a-z]+)', r'\\1_\\2', name)\n",
    "    return re.sub('([a-z0-9])([A-Z])', r'\\1_\\2', s1).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.map(camelcase_to_snakecase)\n",
    "df.rename(columns={'hipertension':'hypertension', 'handcap':'handicap'}, inplace=True)\n",
    "df.sort_values([\"scheduled_day\",\"appointment_day\"], inplace=True, ascending=True) \n",
    "mean_income.rename(columns={mean_income.columns[0]: 'neighbourhood', mean_income.columns[1]: 'neigh_mean_income'}, inplace=True)\n",
    "income_ranges.rename(columns={\"Mesorregiões, microrregiões, municípios, distritos, subdistritos e bairros\":\n",
    "                                'neighbourhood',\n",
    "                            \"Sem rendimento (2)\": 'neigh_income_range_0',\n",
    "                            \"Até ½ salário mínimo\": 'neigh_income_range_1',\n",
    "                            \"Mais de 1/2 a 1 salário mínimo\": 'neigh_income_range_2',\n",
    "                            \"Mais de 1 a 2 salário mínimo\": 'neigh_income_range_3',\n",
    "                            \"Mais de 2 a 5 salário mínimo\": 'neigh_income_range_4',\n",
    "                            \"Mais de 5 a 10 salário mínimo\": 'neigh_income_range_5',\n",
    "                            \"Mais de 10 a 20 salário mínimo\": 'neigh_income_range_6',\n",
    "                            \"Mais de 20 salário mínimo\": 'neigh_income_range_7',\n",
    "                            },\n",
    "                    inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes: [0 1]\n",
      "alcoholism: [0 1]\n",
      "hypertension: [0 1]\n",
      "handicap: [0 1 2 3 4]\n",
      "scholarship: [0 1]\n",
      "sms_received: [1 0]\n",
      "neighbourhood: ['resistencia' 'vila rubim' 'sao cristovao' 'maruipe' 'santa cecilia'\n",
      " 'tabuazeiro' 'caratoira' 'conquista' 'santos dumont' 'santo andre'\n",
      " 'redencao' 'bento ferreira' 'monte belo' 'gurigica' 'jucutuquara'\n",
      " 'praia do canto' 'consolacao' 'cruzamento' 'bela vista' 'centro'\n",
      " 'santa lucia' 'ilha de santa maria' 'jardim camburi' 'jardim da penha'\n",
      " 'santa clara' 'bonfim' 'jesus de nazareth' 'jabour' 'sao jose'\n",
      " 'sao pedro' 'santo antonio' 'maria ortiz' 'itarare' 'santa tereza'\n",
      " 'universitario' 'inhangueta' 'ilha do principe' 'romao' 'santa martha'\n",
      " 'andorinhas' 'santa luiza' 'da penha' 'do quadro' 'parque moscoso'\n",
      " 'grande vitoria' 'forte sao joao' \"joana d'arc\" 'de lourdes'\n",
      " 'santos reis' 'ariovaldo favalessa' 'horto' 'fonte grande' 'goiabeiras'\n",
      " 'sao benedito' 'nova palestina' 'enseada do sua' 'do cabral' 'piedade'\n",
      " 'republica' 'do moscoso' 'ilha das caieiras' 'fradinhos' 'nazareth'\n",
      " 'seguranca do lar' 'mario cypreste' 'pontal de camburi' 'estrelinha'\n",
      " 'praia do sua' 'solon borges' 'mata da praia' 'antonio honorio' 'comdusa'\n",
      " 'boa vista' 'morada de camburi' 'santa helena' 'ilha do boi'\n",
      " 'barro vermelho' 'ilha do frade' 'parque industrial']\n"
     ]
    }
   ],
   "source": [
    "def strip_accents(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "df.neighbourhood = df.neighbourhood.str.lower()\n",
    "mean_income.neighbourhood = mean_income.neighbourhood.str.lower()\n",
    "income_ranges.neighbourhood = income_ranges.neighbourhood.str.lower()\n",
    "\n",
    "df.neighbourhood = df.neighbourhood.apply(strip_accents)\n",
    "mean_income.neighbourhood = mean_income.neighbourhood.apply(strip_accents)\n",
    "income_ranges.neighbourhood = income_ranges.neighbourhood.apply(strip_accents)\n",
    "\n",
    "# aeroporto isn't a real neighbourhood, changing to nearest one\n",
    "df.loc[df.neighbourhood == \"aeroporto\", \"neighbourhood\"] = \"jardim camburi\"\n",
    "# Fixes apostrophe\n",
    "df.loc[df.neighbourhood == \"joana d´arc\", \"neighbourhood\"] = \"joana d'arc\"\n",
    "# removing 2 patients from island\n",
    "df = df[df.neighbourhood != \"ilhas oceanicas de trindade\"]\n",
    "\n",
    "df = pd.merge(df, mean_income, left_on=\"neighbourhood\", right_on=\"neighbourhood\", how='left', sort=False)\n",
    "# Check if there is any missing neighbourhood\n",
    "df.loc[df.neigh_mean_income.isnull(), [\"neighbourhood\", \"neigh_mean_income\"]]\n",
    "\n",
    "df = pd.merge(df, income_ranges, left_on=\"neighbourhood\", right_on=\"neighbourhood\", how='left', sort=False)\n",
    "# Check if there is any missing neighbourhood\n",
    "df.loc[df.neigh_income_range_0.isnull(), [\"neighbourhood\", \"neigh_income_range_0\"]]\n",
    "\n",
    "df[\"no-show\"] = df[\"no-show\"].map({\"Yes\": True, \"No\": False})\n",
    "df[\"show\"] = ~df[\"no-show\"]\n",
    "del[df[\"no-show\"]]\n",
    "\n",
    "for feature in [\"diabetes\", \"alcoholism\", \"hypertension\", \"handicap\", \"scholarship\", \"sms_received\", \"neighbourhood\"]: print(\"{}: {}\".format(feature, df[feature].unique()))\n",
    "boolean_features = [\"diabetes\", \"alcoholism\", \"hypertension\", \"sms_received\", \"scholarship\"]\n",
    "categorical_features = [\"gender\", \"handicap\", \"neighbourhood\", \"patient_id\", \"appointment_id\"]\n",
    "\n",
    "#df.age = df.age.astype(\"int\")\n",
    "#df.patient_id = df.patient_id.astype(\"int\")\n",
    "#df.appointment_id = df.appointment_id.astype(\"int\")\n",
    "\n",
    "for feature in boolean_features:\n",
    "    df[feature] = df[feature].astype(\"bool\")\n",
    "\n",
    "for feature in categorical_features:\n",
    "    df[feature] = df[feature].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derived Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_prior_noshow(row):\n",
    "    previous_appoint = df.loc[(df.patient_id == row[\"patient_id\"]) & (df.appointment_day <= row[\"scheduled_day\"]), \"show\"]\n",
    "    row[\"previous_appoint_count\"] = len(previous_appoint)\n",
    "    row[\"previous_appoint_shows\"] = previous_appoint.sum()\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"days_delta\"] = (df.appointment_day - pd.to_datetime(df.scheduled_day.dt.date)).dt.days\n",
    "df = df.apply(calculate_prior_noshow, axis=1)\n",
    "df = df.drop([\"patient_id\", \"appointment_id\"], axis=1)\n",
    "df.age = df.age.astype(\"int\")\n",
    "df.loc[df.age < 0, \"age\"] = int(df.age.mode())\n",
    "df.loc[df.days_delta < 0, \"days_delta\"] = int(df.days_delta.mode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>scheduled_day</th>\n",
       "      <th>appointment_day</th>\n",
       "      <th>age</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>scholarship</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>alcoholism</th>\n",
       "      <th>handicap</th>\n",
       "      <th>...</th>\n",
       "      <th>neigh_income_range_3</th>\n",
       "      <th>neigh_income_range_4</th>\n",
       "      <th>neigh_income_range_5</th>\n",
       "      <th>neigh_income_range_6</th>\n",
       "      <th>neigh_income_range_7</th>\n",
       "      <th>neigh_income_range_0</th>\n",
       "      <th>show</th>\n",
       "      <th>days_delta</th>\n",
       "      <th>previous_appoint_count</th>\n",
       "      <th>previous_appoint_shows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>2015-11-10 07:13:56</td>\n",
       "      <td>2016-05-04</td>\n",
       "      <td>51</td>\n",
       "      <td>resistencia</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254717</td>\n",
       "      <td>0.080370</td>\n",
       "      <td>0.008708</td>\n",
       "      <td>0.001270</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>0.364840</td>\n",
       "      <td>True</td>\n",
       "      <td>176</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>2015-12-03 08:17:28</td>\n",
       "      <td>2016-05-02</td>\n",
       "      <td>34</td>\n",
       "      <td>vila rubim</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.224314</td>\n",
       "      <td>0.179608</td>\n",
       "      <td>0.063529</td>\n",
       "      <td>0.012549</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.308235</td>\n",
       "      <td>False</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>2015-12-07 10:40:59</td>\n",
       "      <td>2016-06-03</td>\n",
       "      <td>27</td>\n",
       "      <td>sao cristovao</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225615</td>\n",
       "      <td>0.190759</td>\n",
       "      <td>0.062416</td>\n",
       "      <td>0.009727</td>\n",
       "      <td>0.002162</td>\n",
       "      <td>0.310997</td>\n",
       "      <td>False</td>\n",
       "      <td>179</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>2015-12-07 10:42:42</td>\n",
       "      <td>2016-06-03</td>\n",
       "      <td>48</td>\n",
       "      <td>maruipe</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.184203</td>\n",
       "      <td>0.250071</td>\n",
       "      <td>0.132022</td>\n",
       "      <td>0.032221</td>\n",
       "      <td>0.007129</td>\n",
       "      <td>0.273453</td>\n",
       "      <td>True</td>\n",
       "      <td>179</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>2015-12-07 10:43:01</td>\n",
       "      <td>2016-06-03</td>\n",
       "      <td>80</td>\n",
       "      <td>sao cristovao</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225615</td>\n",
       "      <td>0.190759</td>\n",
       "      <td>0.062416</td>\n",
       "      <td>0.009727</td>\n",
       "      <td>0.002162</td>\n",
       "      <td>0.310997</td>\n",
       "      <td>True</td>\n",
       "      <td>179</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender       scheduled_day appointment_day  age  neighbourhood  scholarship  \\\n",
       "0      F 2015-11-10 07:13:56      2016-05-04   51    resistencia        False   \n",
       "1      M 2015-12-03 08:17:28      2016-05-02   34     vila rubim        False   \n",
       "2      F 2015-12-07 10:40:59      2016-06-03   27  sao cristovao         True   \n",
       "3      F 2015-12-07 10:42:42      2016-06-03   48        maruipe        False   \n",
       "4      F 2015-12-07 10:43:01      2016-06-03   80  sao cristovao        False   \n",
       "\n",
       "   hypertension  diabetes  alcoholism  handicap           ...            \\\n",
       "0         False     False       False         0           ...             \n",
       "1          True     False       False         0           ...             \n",
       "2         False     False       False         0           ...             \n",
       "3          True      True       False         0           ...             \n",
       "4          True      True       False         0           ...             \n",
       "\n",
       "   neigh_income_range_3  neigh_income_range_4  neigh_income_range_5  \\\n",
       "0              0.254717              0.080370              0.008708   \n",
       "1              0.224314              0.179608              0.063529   \n",
       "2              0.225615              0.190759              0.062416   \n",
       "3              0.184203              0.250071              0.132022   \n",
       "4              0.225615              0.190759              0.062416   \n",
       "\n",
       "   neigh_income_range_6  neigh_income_range_7  neigh_income_range_0   show  \\\n",
       "0              0.001270              0.000363              0.364840   True   \n",
       "1              0.012549              0.000784              0.308235  False   \n",
       "2              0.009727              0.002162              0.310997  False   \n",
       "3              0.032221              0.007129              0.273453   True   \n",
       "4              0.009727              0.002162              0.310997   True   \n",
       "\n",
       "   days_delta  previous_appoint_count  previous_appoint_shows  \n",
       "0         176                       0                       0  \n",
       "1         151                       0                       0  \n",
       "2         179                       0                       0  \n",
       "3         179                       0                       0  \n",
       "4         179                       0                       0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_features = pd.get_dummies(df.drop([\"show\", \"neighbourhood\", \"alcoholism\", \"gender\",'scheduled_day', 'appointment_day','neigh_income_range_1', 'neigh_income_range_2',\n",
    "       'neigh_income_range_3', 'neigh_income_range_4', 'neigh_income_range_5',\n",
    "       'neigh_income_range_6', 'neigh_income_range_7', 'neigh_income_range_0'], axis=1)).columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'scholarship', 'hypertension', 'diabetes', 'handicap',\n",
       "       'sms_received', 'neigh_mean_income', 'days_delta',\n",
       "       'previous_appoint_count', 'previous_appoint_shows'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(df.drop([\"show\", \"neighbourhood\", \"alcoholism\", \"gender\",'scheduled_day', 'appointment_day','neigh_income_range_1', 'neigh_income_range_2',\n",
    "       'neigh_income_range_3', 'neigh_income_range_4', 'neigh_income_range_5',\n",
    "       'neigh_income_range_6', 'neigh_income_range_7', 'neigh_income_range_0'], axis=1)).values\n",
    "y = df.show.values\n",
    "X = X.astype(\"float64\")\n",
    "y = y.astype(\"float64\")\n",
    "\n",
    "X = df[one_hot_features]\n",
    "y = df[\"show\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=.3, random_state=7, shuffle = True)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=.5, random_state=7, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sumit.ghose.roy\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "model_rf = rf.fit(X_train,y_train)\n",
    "y_pred_rf = model_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Mean AUC Score ===\n",
      "Mean AUC Score - Random Forest Classifier :  0.6487779084248657\n",
      "Confusion Matrix :\n",
      " [[0.28912387 0.71087613]\n",
      " [0.12291808 0.87708192]]\n"
     ]
    }
   ],
   "source": [
    "rf_cv_score = cross_val_score(model_rf, X, y, cv=10, scoring='roc_auc')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - Random Forest Classifier : \", rf_cv_score.mean())\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_rf.round())\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print('Confusion Matrix :\\n', cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc = XGBClassifier(n_estimators=400, scale_pos_weight=((y_train == 0).sum() / y_train.sum()))\n",
    "model_xgb = xgbc.fit(X_train, y_train)\n",
    "y_pred_xgb = model_xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sumit.ghose.roy\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "model_xgb = xgbc.fit(X_train.as_matrix(), y_train.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Mean AUC Score ===\n",
      "Mean AUC Score - XGB Classifier :  0.7108830226915961\n",
      "Confusion Matrix :\n",
      " [[0.87039275 0.12960725]\n",
      " [0.47117341 0.52882659]]\n"
     ]
    }
   ],
   "source": [
    "xgb_cv_score = cross_val_score(model_xgb, X, y, cv=10, scoring='roc_auc')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - XGB Classifier : \", xgb_cv_score.mean())\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_xgb.round())\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print('Confusion Matrix :\\n', cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sumit.ghose.roy\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.71237177, 0.28762823]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb.predict_proba(X_val.as_matrix()[0].reshape(1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = np.array([55, 0,0 ,0, 0, 1, 300, 0,0 ,0 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9829217, 0.0170783]], dtype=float32)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb.predict_proba(inp.reshape(1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {'age' : [13],\n",
    "       'scholarship': True,\n",
    "       'hypertension': False, \n",
    "       'diabetes': False, \n",
    "       'handicap': 0,\n",
    "       'sms_received': True, \n",
    "        'neigh_mean_income' : 510, \n",
    "        'days_delta': 13,\n",
    "       'previous_appoint_count':0, \n",
    "        'previous_appoint_shows':0} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inp = pd.DataFrame(dict, columns=['age', 'scholarship','hypertension','diabetes','handicap','sms_received','neigh_mean_income','days_delta','previous_appoint_count','previous_appoint_shows'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>scholarship</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>handicap</th>\n",
       "      <th>sms_received</th>\n",
       "      <th>neigh_mean_income</th>\n",
       "      <th>days_delta</th>\n",
       "      <th>previous_appoint_count</th>\n",
       "      <th>previous_appoint_shows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>510</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  scholarship  hypertension  diabetes  handicap  sms_received  \\\n",
       "0   13         True         False     False         0          True   \n",
       "\n",
       "   neigh_mean_income  days_delta  previous_appoint_count  \\\n",
       "0                510          13                       0   \n",
       "\n",
       "   previous_appoint_shows  \n",
       "0                       0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71237177"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb.predict_proba(df_inp)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_features_val =  {'age' : [13],\n",
    "       'scholarship': True,\n",
    "       'hypertension': False, \n",
    "       'diabetes': False, \n",
    "       'handicap': [0],\n",
    "       'sms_received': True, \n",
    "        'neigh_mean_income' : [510], \n",
    "        'days_delta': [13],\n",
    "       'previous_appoint_count':[0], \n",
    "        'previous_appoint_shows':[0]} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71237177"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_features = ['age', 'scholarship','hypertension','diabetes','handicap','sms_received','neigh_mean_income','days_delta','previous_appoint_count','previous_appoint_shows']\n",
    "df_inp = pd.DataFrame(dict_features_val, columns=dict_features)\n",
    "model_xgb.predict_proba(df_inp)[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate pickle file with XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model to disk\n",
    "pickle.dump(model_xgb, open('model_f.pkl', 'wb'))\n",
    "\n",
    "#Loading model to compare the results\n",
    "model = pickle.load(open('model_f.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
